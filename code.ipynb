{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/60116208/pytorch-load-dataset-of-grayscale-images\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chickenpox', 'Measles', 'Monkeypox', 'Normal']\n",
      "{'Chickenpox': 0, 'Measles': 1, 'Monkeypox': 2, 'Normal': 3}\n"
     ]
    }
   ],
   "source": [
    "root = 'data/'\n",
    "\n",
    "data_transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                     transforms.Resize((64,64)),\n",
    "                                     transforms.ToTensor()])\n",
    "dataset = ImageFolder(root, transform=data_transform)\n",
    "\n",
    "print(dataset.classes)\n",
    "print(dataset.class_to_idx)\n",
    "\n",
    "# Split test and train dataset \n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Set batch size of train data loader\n",
    "batch_size_train = 20\n",
    "\n",
    "# Set batch size of test data loader\n",
    "batch_size_test = 22\n",
    "\n",
    "# load the split train and test data into batches via DataLoader()\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "label_map={\n",
    "    0:\"Chickenpox\",\n",
    "    1:\"Measles\",\n",
    "    2:\"Monkeypox\",\n",
    "    3:\"Normal\"\n",
    "}\n",
    "classes = ('Chickenpox', 'Measles', 'Monkeypox', 'Normal')\n",
    "\n",
    "dataloaders={}\n",
    "dataloaders[\"train\"]=train_loader\n",
    "dataloaders[\"val\"]=test_loader\n",
    "\n",
    "dataset_sizes = {\"train\":len(train_loader.dataset),\"val\":len(test_loader.dataset)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normal')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looping through it, get a batch on each loop \n",
    "for images, labels in train_loader:\n",
    "    pass\n",
    "\n",
    "# Get one batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "indx=10\n",
    "plt.imshow(images[indx].reshape(64,64))\n",
    "plt.title(label_map[int(labels[indx].numpy())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs=30\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.repeat(1, 3, 1, 1)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "def accuracy(model, test_loader) :\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_corrects=0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.repeat(1, 3, 1, 1)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device) \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        acc = running_corrects.double() / dataset_sizes[\"val\"]\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Counter({2: 439, 3: 428, 0: 249, 1: 216})\n",
      "Test: Counter({2: 191, 3: 157, 0: 127, 1: 97})\n",
      "Total: {0: 376, 1: 313, 2: 630, 3: 585}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "train_classes = [dataset.targets[i] for i in train_data.indices]\n",
    "print(\"train:\",Counter(train_classes)) # if doesn' work: Counter(i.item() for i in train_classes)\n",
    "\n",
    "test_classes = [dataset.targets[i] for i in test_data.indices]\n",
    "print(\"Test:\",Counter(test_classes)) # if doesn' work: Counter(i.item() for i in train_classes)\n",
    "\n",
    "print(\"Total:\",dict(Counter(test_data.dataset.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './resnet18_net.pth'\n",
    "\n",
    "# setup\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model_ft3 = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft3.fc.in_features\n",
    "model_ft3.fc = nn.Linear(num_ftrs, len(classes))\n",
    "model_ft3.to(device)\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0691 Acc: 0.5368\n",
      "val Loss: 0.9278 Acc: 0.6486\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4686 Acc: 0.8086\n",
      "val Loss: 0.8326 Acc: 0.6923\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2844 Acc: 0.8934\n",
      "val Loss: 0.7692 Acc: 0.7063\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2159 Acc: 0.9152\n",
      "val Loss: 0.5397 Acc: 0.7937\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1805 Acc: 0.9317\n",
      "val Loss: 1.0242 Acc: 0.6976\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1224 Acc: 0.9565\n",
      "val Loss: 0.6539 Acc: 0.7710\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0883 Acc: 0.9737\n",
      "val Loss: 0.6372 Acc: 0.7797\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0545 Acc: 0.9857\n",
      "val Loss: 0.6539 Acc: 0.7920\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0531 Acc: 0.9872\n",
      "val Loss: 0.6410 Acc: 0.7850\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0458 Acc: 0.9887\n",
      "val Loss: 0.6418 Acc: 0.7885\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0329 Acc: 0.9940\n",
      "val Loss: 0.6473 Acc: 0.7920\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0476 Acc: 0.9865\n",
      "val Loss: 0.6503 Acc: 0.7780\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.9940\n",
      "val Loss: 0.6483 Acc: 0.7920\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0308 Acc: 0.9962\n",
      "val Loss: 0.6779 Acc: 0.7902\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0430 Acc: 0.9872\n",
      "val Loss: 0.6509 Acc: 0.7955\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0377 Acc: 0.9925\n",
      "val Loss: 0.6752 Acc: 0.7850\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0333 Acc: 0.9947\n",
      "val Loss: 0.6801 Acc: 0.7885\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0248 Acc: 0.9970\n",
      "val Loss: 0.6345 Acc: 0.7937\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0344 Acc: 0.9932\n",
      "val Loss: 0.6474 Acc: 0.7885\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0378 Acc: 0.9902\n",
      "val Loss: 0.6558 Acc: 0.7937\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0301 Acc: 0.9955\n",
      "val Loss: 0.6370 Acc: 0.7972\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0293 Acc: 0.9955\n",
      "val Loss: 0.6326 Acc: 0.7990\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0296 Acc: 0.9955\n",
      "val Loss: 0.6614 Acc: 0.7867\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0284 Acc: 0.9962\n",
      "val Loss: 0.6534 Acc: 0.7885\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0316 Acc: 0.9940\n",
      "val Loss: 0.6613 Acc: 0.7937\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0274 Acc: 0.9970\n",
      "val Loss: 0.6641 Acc: 0.7902\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0358 Acc: 0.9917\n",
      "val Loss: 0.6564 Acc: 0.7885\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0317 Acc: 0.9940\n",
      "val Loss: 0.6506 Acc: 0.7885\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0285 Acc: 0.9940\n",
      "val Loss: 0.6576 Acc: 0.7885\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0329 Acc: 0.9955\n",
      "val Loss: 0.6542 Acc: 0.7937\n",
      "\n",
      "Training complete in 5m 41s\n",
      "Best val Acc: 0.798951\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9423, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9423, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './alex_net.pth'\n",
    "\n",
    "# setup\n",
    "model_ft = models.alexnet(pretrained=True,)\n",
    "model_ft.classifier[6] = nn.Linear(4096,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model_ft3 = models.alexnet(pretrained=True)\n",
    "model_ft3.classifier[6] = nn.Linear(4096,len(classes))\n",
    "model_ft3.to(device)\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.2148 Acc: 0.4842\n",
      "val Loss: 1.0539 Acc: 0.5664\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.9269 Acc: 0.6141\n",
      "val Loss: 0.9223 Acc: 0.6119\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.8132 Acc: 0.6689\n",
      "val Loss: 0.8622 Acc: 0.6101\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.7476 Acc: 0.6854\n",
      "val Loss: 0.8747 Acc: 0.6119\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.6387 Acc: 0.7252\n",
      "val Loss: 0.8555 Acc: 0.6608\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.5438 Acc: 0.7748\n",
      "val Loss: 0.7884 Acc: 0.6748\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.4531 Acc: 0.8131\n",
      "val Loss: 0.7430 Acc: 0.6643\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.2928 Acc: 0.8941\n",
      "val Loss: 0.6561 Acc: 0.7220\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.2403 Acc: 0.9092\n",
      "val Loss: 0.6515 Acc: 0.7203\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.2097 Acc: 0.9234\n",
      "val Loss: 0.6619 Acc: 0.7255\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.2038 Acc: 0.9219\n",
      "val Loss: 0.6565 Acc: 0.7220\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.1922 Acc: 0.9294\n",
      "val Loss: 0.6722 Acc: 0.7185\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.1723 Acc: 0.9377\n",
      "val Loss: 0.6648 Acc: 0.7220\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.1693 Acc: 0.9422\n",
      "val Loss: 0.6745 Acc: 0.7255\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.1520 Acc: 0.9512\n",
      "val Loss: 0.6744 Acc: 0.7273\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.1446 Acc: 0.9542\n",
      "val Loss: 0.6735 Acc: 0.7238\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.1511 Acc: 0.9505\n",
      "val Loss: 0.6750 Acc: 0.7255\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.1467 Acc: 0.9489\n",
      "val Loss: 0.6746 Acc: 0.7238\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.1437 Acc: 0.9527\n",
      "val Loss: 0.6774 Acc: 0.7238\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.1446 Acc: 0.9505\n",
      "val Loss: 0.6785 Acc: 0.7290\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.1479 Acc: 0.9497\n",
      "val Loss: 0.6765 Acc: 0.7273\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.1489 Acc: 0.9497\n",
      "val Loss: 0.6766 Acc: 0.7255\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.1465 Acc: 0.9497\n",
      "val Loss: 0.6765 Acc: 0.7273\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.1417 Acc: 0.9497\n",
      "val Loss: 0.6769 Acc: 0.7273\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.1429 Acc: 0.9542\n",
      "val Loss: 0.6766 Acc: 0.7255\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.1444 Acc: 0.9602\n",
      "val Loss: 0.6771 Acc: 0.7273\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.1401 Acc: 0.9505\n",
      "val Loss: 0.6774 Acc: 0.7273\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.1500 Acc: 0.9527\n",
      "val Loss: 0.6774 Acc: 0.7273\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.1408 Acc: 0.9550\n",
      "val Loss: 0.6775 Acc: 0.7273\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.1344 Acc: 0.9587\n",
      "val Loss: 0.6775 Acc: 0.7273\n",
      "\n",
      "Training complete in 5m 3s\n",
      "Best val Acc: 0.729021\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9021, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### densenet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './densenet121.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_ft = models.densenet121(pretrained=True,)\n",
    "model_ft.classifier=nn.Linear(1024,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.9855 Acc: 0.5781\n",
      "val Loss: 0.6621 Acc: 0.7080\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.5064 Acc: 0.7905\n",
      "val Loss: 0.5588 Acc: 0.7255\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.3218 Acc: 0.8619\n",
      "val Loss: 0.5623 Acc: 0.7465\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2344 Acc: 0.9107\n",
      "val Loss: 0.4963 Acc: 0.7955\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1545 Acc: 0.9452\n",
      "val Loss: 0.5818 Acc: 0.7675\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1026 Acc: 0.9640\n",
      "val Loss: 0.5560 Acc: 0.7937\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0927 Acc: 0.9692\n",
      "val Loss: 0.6066 Acc: 0.7832\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0654 Acc: 0.9835\n",
      "val Loss: 0.6022 Acc: 0.8059\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0562 Acc: 0.9857\n",
      "val Loss: 0.6271 Acc: 0.8059\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.9865\n",
      "val Loss: 0.6093 Acc: 0.8077\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0394 Acc: 0.9925\n",
      "val Loss: 0.6042 Acc: 0.8077\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0391 Acc: 0.9925\n",
      "val Loss: 0.6128 Acc: 0.7867\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.9917\n",
      "val Loss: 0.6145 Acc: 0.8059\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0429 Acc: 0.9910\n",
      "val Loss: 0.6234 Acc: 0.8112\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0267 Acc: 0.9970\n",
      "val Loss: 0.6153 Acc: 0.8042\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0405 Acc: 0.9887\n",
      "val Loss: 0.6064 Acc: 0.8042\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0305 Acc: 0.9955\n",
      "val Loss: 0.6160 Acc: 0.8094\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0329 Acc: 0.9947\n",
      "val Loss: 0.6138 Acc: 0.8094\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9955\n",
      "val Loss: 0.6095 Acc: 0.8094\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0333 Acc: 0.9925\n",
      "val Loss: 0.6201 Acc: 0.8059\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0262 Acc: 0.9947\n",
      "val Loss: 0.6214 Acc: 0.8077\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0276 Acc: 0.9962\n",
      "val Loss: 0.6165 Acc: 0.8112\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0288 Acc: 0.9955\n",
      "val Loss: 0.6064 Acc: 0.8024\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0357 Acc: 0.9902\n",
      "val Loss: 0.6095 Acc: 0.8042\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0404 Acc: 0.9917\n",
      "val Loss: 0.6210 Acc: 0.8077\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0263 Acc: 0.9955\n",
      "val Loss: 0.6157 Acc: 0.8007\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0357 Acc: 0.9902\n",
      "val Loss: 0.5994 Acc: 0.8077\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0343 Acc: 0.9925\n",
      "val Loss: 0.6164 Acc: 0.8059\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0356 Acc: 0.9925\n",
      "val Loss: 0.6065 Acc: 0.8059\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0313 Acc: 0.9947\n",
      "val Loss: 0.6226 Acc: 0.8007\n",
      "\n",
      "Training complete in 14m 26s\n",
      "Best val Acc: 0.811189\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9458, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "model_ft3 = models.densenet121(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(1024,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8112, dtype=torch.float64)\n",
      "tensor(0.8112, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### densenet161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './densenet161.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.densenet161(pretrained=True,)\n",
    "model_ft.classifier=nn.Linear(2208,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.9851 Acc: 0.5848\n",
      "val Loss: 0.9174 Acc: 0.6066\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8234, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "model_ft3 = models.densenet161(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(2208,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "\n",
    "print(accuracy(model_ft3, test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### densenet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1664, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "PATH = './densenet169.pth'\n",
    "\n",
    "model_ft = models.densenet169(pretrained=True,)\n",
    "print(model_ft.classifier)\n",
    "model_ft.classifier=nn.Linear(1664,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "#test\n",
    "model_ft3 = models.densenet169(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(1664,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "\n",
    "print(accuracy(model_ft3, test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0273 Acc: 0.5623\n",
      "val Loss: 0.6742 Acc: 0.7343\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.5404 Acc: 0.7688\n",
      "val Loss: 0.4912 Acc: 0.7955\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.3692 Acc: 0.8483\n",
      "val Loss: 0.4655 Acc: 0.7972\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2323 Acc: 0.9062\n",
      "val Loss: 0.5805 Acc: 0.7657\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1626 Acc: 0.9437\n",
      "val Loss: 0.5288 Acc: 0.7955\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1296 Acc: 0.9535\n",
      "val Loss: 0.6158 Acc: 0.7920\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0966 Acc: 0.9685\n",
      "val Loss: 0.5652 Acc: 0.8147\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0734 Acc: 0.9767\n",
      "val Loss: 0.5661 Acc: 0.8059\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0561 Acc: 0.9842\n",
      "val Loss: 0.5721 Acc: 0.8007\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0537 Acc: 0.9880\n",
      "val Loss: 0.5821 Acc: 0.8042\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 0.9895\n",
      "val Loss: 0.5572 Acc: 0.8147\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0349 Acc: 0.9932\n",
      "val Loss: 0.5434 Acc: 0.8199\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0319 Acc: 0.9955\n",
      "val Loss: 0.5651 Acc: 0.8094\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0300 Acc: 0.9947\n",
      "val Loss: 0.5680 Acc: 0.8147\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0306 Acc: 0.9955\n",
      "val Loss: 0.5589 Acc: 0.8094\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0394 Acc: 0.9917\n",
      "val Loss: 0.5690 Acc: 0.8182\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 0.9917\n",
      "val Loss: 0.5644 Acc: 0.8129\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0341 Acc: 0.9940\n",
      "val Loss: 0.5931 Acc: 0.8059\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9925\n",
      "val Loss: 0.5715 Acc: 0.8112\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0399 Acc: 0.9902\n",
      "val Loss: 0.5819 Acc: 0.8042\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0288 Acc: 0.9962\n",
      "val Loss: 0.5877 Acc: 0.8112\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0258 Acc: 0.9970\n",
      "val Loss: 0.5627 Acc: 0.8182\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9955\n",
      "val Loss: 0.5546 Acc: 0.8129\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9932\n",
      "val Loss: 0.5728 Acc: 0.8129\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0279 Acc: 0.9955\n",
      "val Loss: 0.5666 Acc: 0.8059\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 0.9902\n",
      "val Loss: 0.5608 Acc: 0.8129\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0308 Acc: 0.9932\n",
      "val Loss: 0.5744 Acc: 0.8077\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0291 Acc: 0.9955\n",
      "val Loss: 0.5767 Acc: 0.8129\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0322 Acc: 0.9947\n",
      "val Loss: 0.5791 Acc: 0.8077\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0257 Acc: 0.9970\n",
      "val Loss: 0.5637 Acc: 0.8094\n",
      "\n",
      "Training complete in 21m 41s\n",
      "Best val Acc: 0.819930\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8199, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### densenet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './densenet201.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.densenet201(pretrained=True,)\n",
    "# print(model_ft.classifier)\n",
    "model_ft.classifier=nn.Linear(1920,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0028 Acc: 0.5563\n",
      "val Loss: 0.7860 Acc: 0.6713\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.5152 Acc: 0.7755\n",
      "val Loss: 0.6138 Acc: 0.7308\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.3019 Acc: 0.8761\n",
      "val Loss: 0.5090 Acc: 0.7867\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.1915 Acc: 0.9377\n",
      "val Loss: 0.5190 Acc: 0.8024\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1265 Acc: 0.9527\n",
      "val Loss: 0.5533 Acc: 0.7902\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.0975 Acc: 0.9655\n",
      "val Loss: 0.5692 Acc: 0.8059\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0802 Acc: 0.9760\n",
      "val Loss: 0.6513 Acc: 0.8077\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0538 Acc: 0.9887\n",
      "val Loss: 0.5972 Acc: 0.8059\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0377 Acc: 0.9940\n",
      "val Loss: 0.5962 Acc: 0.8077\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0393 Acc: 0.9925\n",
      "val Loss: 0.5950 Acc: 0.8042\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0332 Acc: 0.9947\n",
      "val Loss: 0.5846 Acc: 0.8077\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0276 Acc: 0.9962\n",
      "val Loss: 0.6031 Acc: 0.8059\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0273 Acc: 0.9947\n",
      "val Loss: 0.6005 Acc: 0.8042\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0237 Acc: 0.9985\n",
      "val Loss: 0.6291 Acc: 0.8182\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0298 Acc: 0.9955\n",
      "val Loss: 0.6048 Acc: 0.8059\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0321 Acc: 0.9947\n",
      "val Loss: 0.6293 Acc: 0.8112\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0277 Acc: 0.9947\n",
      "val Loss: 0.6160 Acc: 0.8147\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0240 Acc: 0.9992\n",
      "val Loss: 0.6024 Acc: 0.8042\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0228 Acc: 0.9977\n",
      "val Loss: 0.6167 Acc: 0.8042\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0234 Acc: 0.9977\n",
      "val Loss: 0.6164 Acc: 0.8059\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0266 Acc: 0.9985\n",
      "val Loss: 0.6073 Acc: 0.8059\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0239 Acc: 0.9977\n",
      "val Loss: 0.6178 Acc: 0.8112\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0274 Acc: 0.9955\n",
      "val Loss: 0.6118 Acc: 0.8024\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0299 Acc: 0.9955\n",
      "val Loss: 0.5934 Acc: 0.8024\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0268 Acc: 0.9955\n",
      "val Loss: 0.6181 Acc: 0.8059\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0222 Acc: 0.9977\n",
      "val Loss: 0.6029 Acc: 0.8094\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0273 Acc: 0.9955\n",
      "val Loss: 0.6012 Acc: 0.8199\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0221 Acc: 0.9985\n",
      "val Loss: 0.6049 Acc: 0.8129\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0236 Acc: 0.9955\n",
      "val Loss: 0.6166 Acc: 0.8147\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0244 Acc: 0.9955\n",
      "val Loss: 0.6165 Acc: 0.8164\n",
      "\n",
      "Training complete in 27m 35s\n",
      "Best val Acc: 0.819930\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8199, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "model_ft3 = models.densenet201(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(1920,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeezenet1_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.2914 Acc: 0.4024\n",
      "val Loss: 1.2132 Acc: 0.4248\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.0976 Acc: 0.5203\n",
      "val Loss: 0.9884 Acc: 0.5927\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.9546 Acc: 0.6044\n",
      "val Loss: 0.8255 Acc: 0.6503\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.8907 Acc: 0.6359\n",
      "val Loss: 0.8686 Acc: 0.6503\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.7589 Acc: 0.6862\n",
      "val Loss: 0.7691 Acc: 0.6503\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.7208 Acc: 0.7020\n",
      "val Loss: 0.6769 Acc: 0.7133\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.5873 Acc: 0.7470\n",
      "val Loss: 0.5981 Acc: 0.7028\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.4442 Acc: 0.8026\n",
      "val Loss: 0.5538 Acc: 0.7360\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.4051 Acc: 0.8213\n",
      "val Loss: 0.5525 Acc: 0.7168\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.3808 Acc: 0.8371\n",
      "val Loss: 0.5445 Acc: 0.7430\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.3563 Acc: 0.8491\n",
      "val Loss: 0.5396 Acc: 0.7500\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.3399 Acc: 0.8506\n",
      "val Loss: 0.5431 Acc: 0.7483\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.3402 Acc: 0.8514\n",
      "val Loss: 0.5236 Acc: 0.7448\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.3207 Acc: 0.8566\n",
      "val Loss: 0.5379 Acc: 0.7570\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.3026 Acc: 0.8701\n",
      "val Loss: 0.5339 Acc: 0.7535\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.3101 Acc: 0.8619\n",
      "val Loss: 0.5336 Acc: 0.7552\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.2977 Acc: 0.8769\n",
      "val Loss: 0.5315 Acc: 0.7535\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.2998 Acc: 0.8724\n",
      "val Loss: 0.5310 Acc: 0.7570\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.3074 Acc: 0.8671\n",
      "val Loss: 0.5297 Acc: 0.7517\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.3022 Acc: 0.8776\n",
      "val Loss: 0.5259 Acc: 0.7500\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.2862 Acc: 0.8836\n",
      "val Loss: 0.5241 Acc: 0.7465\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.3067 Acc: 0.8754\n",
      "val Loss: 0.5248 Acc: 0.7448\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.2938 Acc: 0.8836\n",
      "val Loss: 0.5254 Acc: 0.7430\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.2954 Acc: 0.8731\n",
      "val Loss: 0.5255 Acc: 0.7448\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.2866 Acc: 0.8761\n",
      "val Loss: 0.5259 Acc: 0.7448\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.2944 Acc: 0.8776\n",
      "val Loss: 0.5261 Acc: 0.7448\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.2907 Acc: 0.8836\n",
      "val Loss: 0.5262 Acc: 0.7448\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.2940 Acc: 0.8814\n",
      "val Loss: 0.5268 Acc: 0.7448\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.2994 Acc: 0.8769\n",
      "val Loss: 0.5268 Acc: 0.7448\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.2884 Acc: 0.8836\n",
      "val Loss: 0.5268 Acc: 0.7448\n",
      "\n",
      "Training complete in 3m 29s\n",
      "Best val Acc: 0.756993\n",
      "tensor(0.7570, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = './squeezenet1_0.pth'\n",
    "\n",
    "# setup\n",
    "model_ft = models.squeezenet1_0(pretrained=True,)\n",
    "model_ft.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model_ft3 = models.squeezenet1_0(pretrained=True,)\n",
    "model_ft3.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7570, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeezenet1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './squeezenet1_1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.squeezenet1_1(pretrained=True,)\n",
    "# print(model_ft.classifier)\n",
    "model_ft.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.3788 Acc: 0.3258\n",
      "val Loss: 1.2653 Acc: 0.4371\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.2599 Acc: 0.4174\n",
      "val Loss: 1.2406 Acc: 0.3829\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.1754 Acc: 0.4662\n",
      "val Loss: 1.0596 Acc: 0.5787\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.0495 Acc: 0.5571\n",
      "val Loss: 1.0621 Acc: 0.5455\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.9331 Acc: 0.6156\n",
      "val Loss: 0.8485 Acc: 0.6731\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.8868 Acc: 0.6351\n",
      "val Loss: 0.8605 Acc: 0.6591\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.8282 Acc: 0.6569\n",
      "val Loss: 0.9219 Acc: 0.6101\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.6631 Acc: 0.7117\n",
      "val Loss: 0.6918 Acc: 0.6923\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.5833 Acc: 0.7635\n",
      "val Loss: 0.6670 Acc: 0.7273\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.5713 Acc: 0.7643\n",
      "val Loss: 0.6514 Acc: 0.7273\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.5444 Acc: 0.7763\n",
      "val Loss: 0.6415 Acc: 0.7413\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.5216 Acc: 0.7755\n",
      "val Loss: 0.6299 Acc: 0.7343\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.4998 Acc: 0.7800\n",
      "val Loss: 0.6348 Acc: 0.7290\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.4986 Acc: 0.7695\n",
      "val Loss: 0.6452 Acc: 0.7220\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.4578 Acc: 0.7988\n",
      "val Loss: 0.6373 Acc: 0.7290\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.4627 Acc: 0.8003\n",
      "val Loss: 0.6359 Acc: 0.7273\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.4544 Acc: 0.8056\n",
      "val Loss: 0.6321 Acc: 0.7255\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.4596 Acc: 0.8071\n",
      "val Loss: 0.6351 Acc: 0.7360\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.4444 Acc: 0.8101\n",
      "val Loss: 0.6441 Acc: 0.7290\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.4485 Acc: 0.7973\n",
      "val Loss: 0.6354 Acc: 0.7238\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.4522 Acc: 0.8168\n",
      "val Loss: 0.6367 Acc: 0.7290\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.4447 Acc: 0.8071\n",
      "val Loss: 0.6378 Acc: 0.7325\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.4384 Acc: 0.8101\n",
      "val Loss: 0.6383 Acc: 0.7325\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.4399 Acc: 0.8191\n",
      "val Loss: 0.6389 Acc: 0.7343\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.4452 Acc: 0.8078\n",
      "val Loss: 0.6376 Acc: 0.7360\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.4577 Acc: 0.7995\n",
      "val Loss: 0.6374 Acc: 0.7360\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.4403 Acc: 0.8123\n",
      "val Loss: 0.6362 Acc: 0.7343\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.4527 Acc: 0.8056\n",
      "val Loss: 0.6352 Acc: 0.7325\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.4391 Acc: 0.8131\n",
      "val Loss: 0.6352 Acc: 0.7325\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.4417 Acc: 0.8093\n",
      "val Loss: 0.6353 Acc: 0.7325\n",
      "\n",
      "Training complete in 3m 16s\n",
      "Best val Acc: 0.741259\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (6): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft3 = models.squeezenet1_1(pretrained=True,)\n",
    "model_ft3.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7413, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(model_ft3, test_loader))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prune_kernel",
   "language": "python",
   "name": "prune_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
